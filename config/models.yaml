# Model configurations for LLM plot extraction pipeline
# Prioritizes direct APIs for cost efficiency, falls back to OpenRouter

direct_apis:
  anthropic:
    api_key: "${ANTHROPIC_API_KEY}"
    base_url: "https://api.anthropic.com"
    models:
      claude35_sonnet:
        name: "claude-3-5-sonnet-20241022"
        max_tokens: 4000
        temperature: 0.1
        cost_per_token_input: 0.000003
        cost_per_token_output: 0.000015
      claude35_haiku:
        name: "claude-3-5-haiku-20241022"
        max_tokens: 4000
        temperature: 0.1
        cost_per_token_input: 0.0000008
        cost_per_token_output: 0.000004
  
  openai:
    api_key: "${OPENAI_API_KEY}"
    base_url: "https://api.openai.com/v1"
    models:
      gpt4o:
        name: "gpt-4o"
        max_tokens: 4000
        temperature: 0.1
        cost_per_token_input: 0.0000025
        cost_per_token_output: 0.00001
      gpt4o_mini:
        name: "gpt-4o-mini"
        max_tokens: 4000
        temperature: 0.1
        cost_per_token_input: 0.00000015
        cost_per_token_output: 0.0000006

# OpenRouter fallback for models not available directly
openrouter:
  api_key: "${OPENROUTER_API_KEY}"
  base_url: "https://openrouter.ai/api/v1"
  models:
    opus:
      name: "anthropic/claude-3-opus"
      max_tokens: 4000
      temperature: 0.1
    gemini_pro:
      name: "google/gemini-pro-vision"
      max_tokens: 4000
      temperature: 0.1
    gemini_flash:
      name: "google/gemini-flash-1.5"
      max_tokens: 4000
      temperature: 0.1